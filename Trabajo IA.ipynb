{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio sobre Q-Learning y algunas de sus variaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el notebook que se ha utilizado para la realización del proyecto realizado por José Manuel Rojas Granado y Javier Solís García.\n",
    "\n",
    "En la primera parte del notebook se muestra el código utilizado para la realización de los algoritmos:\n",
    "\n",
    "1.  Q_Learning perteneciente a la fase 1 del proyecto\n",
    "2.  Q_Learning perteneciente a la fase 2 del proyecto\n",
    "3.  Algoritmo SARSA que se añadido como implementación del proyecto\n",
    "\n",
    "En la segunda parte del notebook se encuentra la función main, en la que si se ejecuta se podrán introducir los diferentes datos y se podrá probar los diferentes ejemplos que se han adjuntado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerias utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_txt(fichero):\n",
    "    path = os.path.join(os.getcwd(), fichero)\n",
    "    lineas = csv.reader(open(path, newline='\\n'))\n",
    "    data = []\n",
    "        \n",
    "        \n",
    "    for linea in lineas:\n",
    "        fila = []\n",
    "        for i in range(0, len(linea)):\n",
    "            fila.append(int(linea[i]))\n",
    "        data.append(fila)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_matriz_recompensas(data, fin):\n",
    "    \n",
    "    cantidad = len(data)*len(data[0])\n",
    "    \n",
    "    lista = []\n",
    "    for i in range(0, cantidad):\n",
    "        lista.append([-1]*cantidad)\n",
    "    \n",
    "    #Definir vecinos\n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        for j in range(0, len(data[i])):\n",
    "            actual = data[i][j]\n",
    "            \n",
    "        \n",
    "            \n",
    "            if len(data)  > i+1:\n",
    "                vecino1 = data[i+1][j]\n",
    "                if vecino1 == fin:\n",
    "                    lista[actual][vecino1] = 100\n",
    "                else:\n",
    "                    lista[actual][vecino1] = 0\n",
    "                    \n",
    "            if 0 <= i-1:\n",
    "                vecino2 = data[i-1][j]\n",
    "                if vecino2 == fin:\n",
    "                    lista[actual][vecino2] = 100\n",
    "                else:\n",
    "                    lista[actual][vecino2] = 0\n",
    "                    \n",
    "            if len(data[i]) > j+1:\n",
    "                vecino3 = data[i][j+1]\n",
    "                if vecino3 == fin:\n",
    "                    lista[actual][vecino3] = 100\n",
    "                else:\n",
    "                    lista[actual][vecino3] = 0\n",
    "                \n",
    "            if 0 <= j-1:\n",
    "                vecino4 = data[i][j-1]\n",
    "                if vecino4 == fin:\n",
    "                    lista[actual][vecino4] = 100\n",
    "                else:\n",
    "                    lista[actual][vecino4] = 0\n",
    "            \n",
    "    lista[fin][fin] = 100\n",
    "    return lista\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializa la matriz Q para el algorimo de Q-Learning, con los pesos de cada\n",
    "#acción inicializados a 0\n",
    "def inicializa_Q(recompensas):\n",
    "   \n",
    "    lista = []\n",
    "    for i in range(0, len(recompensas)):\n",
    "        lista.append([0]*len(recompensas))\n",
    "     \n",
    "    return lista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_matriz_recompensas(fichero):\n",
    "    datos = cargar_datos_txt(fichero)\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos():\n",
    "    \n",
    "    tipo = int(input('''Si quieres que se genere la matriz de recompensas a partir de un tablero pulsa 0,\n",
    "si quieres cargar tu matriz de recompensas pulsa 1: '''))\n",
    "    \n",
    "    inicio = int(input('Introduce el valor de la casilla de inicio: '))\n",
    "    \n",
    "    fin = int(input('Introduce el valor de la casilla objetivo: '))\n",
    "    \n",
    "    epochs = int(input('Introduce el número de episodios de entrenamiento: '))\n",
    "    \n",
    "    gamma = float(input('Introduce el valor del factor de aprendizaje gamma: '))\n",
    "    \n",
    "    tablero = str(input('Introduce el nombre del fichero desde el que quieres cargar la matriz del tablero: '))\n",
    "    \n",
    "    tablero = './' + tablero + '.txt'\n",
    "    \n",
    "    if tipo == 0:\n",
    "        \n",
    "        data = cargar_datos_txt(tablero)\n",
    "    \n",
    "        recompensas = crear_matriz_recompensas(data, fin)\n",
    "    \n",
    "        q = inicializa_Q(recompensas)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        data = cargar_datos_txt(tablero)\n",
    "        \n",
    "        recompensas = str(input('Introduce el nombre del fichero desde el que quieres cargar la matriz de recompensas: '))\n",
    "    \n",
    "        recompensas = './' + recompensas + '.txt'\n",
    "        \n",
    "        recompensas = cargar_datos_txt(recompensas)\n",
    "        \n",
    "        q = inicializa_Q(recompensas)\n",
    "        \n",
    "    \n",
    "    return data, recompensas, q, inicio, fin, epochs, gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de algoritmo de Q-Learning Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_accion_aleatoria(valor, recompensas):\n",
    "    aleatorio = -1\n",
    "    while aleatorio == -1:\n",
    "        casilla = np.random.randint(len(recompensas),size=1)[0]\n",
    "        aleatorio = recompensas[valor][casilla]\n",
    "        \n",
    "    return casilla    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_rendimiento(q):\n",
    "    suma = 0\n",
    "    maximo=1\n",
    "    for i in range(0, len(q)):\n",
    "        suma+=sum(q[i])\n",
    "        if maximo < max(q[i]):\n",
    "            maximo = max(q[i])\n",
    "    return (suma/maximo)*100   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestra_rendimiento(rendimiento):\n",
    "    plt.title('Rendimiento del algoritmo de Q-Learning')\n",
    "    plt.xlabel('Número de episodios de entrenamiento')\n",
    "    plt.ylabel('Valor del rendimiento del algoritmo')\n",
    "    plt.plot(rendimiento)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_camino(q,inicio,fin):\n",
    "    posicion = inicio\n",
    "    camino = []\n",
    "    camino.append(inicio)\n",
    "    converge = True\n",
    "    representacion = ''\n",
    "    \n",
    "    while posicion != fin:\n",
    "        \n",
    "        maximo = max(q[posicion])\n",
    "        siguiente = q[posicion].index(maximo)\n",
    "        posicion = siguiente\n",
    "    \n",
    "        if(posicion in camino):\n",
    "            print('El algoritmo no ha encontrado un camino sin bucles')\n",
    "            converge = False\n",
    "            break\n",
    "\n",
    "        camino.append(siguiente)\n",
    "        \n",
    "    for i in range(len(camino)):\n",
    "        representacion += str(camino[i])+' -> '\n",
    "        \n",
    "    if(converge):    \n",
    "        print('El camino óptimo es: ', representacion[0:-4])\n",
    "        \n",
    "    return camino, converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(data, recompensas, q, fin, epochs, gamma, bol_camino, inicio):\n",
    "    rendimiento = []\n",
    "    for epoch in range(0, epochs):\n",
    "        \n",
    "        print('Época = '+str(epoch), 'Completado al '+str((epoch/epochs)*100)+'%')\n",
    "        i = np.random.randint(len(data) ,size=1)[0]\n",
    "        j = np.random.randint(len(data[i]),size=1)[0]\n",
    "        estado = data[i][j]\n",
    "        primero = True\n",
    "        \n",
    "        while (estado != fin) or (primero):\n",
    "            \n",
    "            accion = seleccionar_accion_aleatoria(estado, recompensas)\n",
    "            maximo = max(q[accion])\n",
    "            q[estado][accion] = recompensas[estado][accion] + gamma*maximo\n",
    "            estado = accion\n",
    "            primero = False\n",
    "            \n",
    "        rendimiento.append(calcula_rendimiento(q))\n",
    "        if bol_camino:\n",
    "            calcular_camino(q, inicio, fin)\n",
    "    print('Entrenamiento finalizado')\n",
    "    return q, rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de algoritmo de Q-Learning Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecionar_accion_aleatoria_F2(estado, recompensas, q, epsilon):\n",
    "    aleatorio = np.random.rand(1)[0]\n",
    "    if aleatorio < epsilon:\n",
    "        res = seleccionar_accion_aleatoria(estado, recompensas)\n",
    "    else:\n",
    "        acciones_posibles =[]\n",
    "        posible=True\n",
    "        acciones = recompensas[estado]#acciones que hay, validas e invalidas\n",
    "        counter = 0\n",
    "        #de las acciones me quedo con el indice de las validas\n",
    "        for i in acciones:\n",
    "            if i >= 0:\n",
    "                acciones_posibles.append(counter)\n",
    "            counter+=1\n",
    "        maximo = max(q[estado])#miro el valor maximo de todas las acciones, que por definición tiene que ser >=0\n",
    "        is_not_max = True\n",
    "        #cojo una acción posible aleatoria que sea igual al maximo posible, esto es porque puede haber varios valores dentro\n",
    "        #de la matriz Q que sean igual de grandes, por ejemplo al principio son todo 0, y hay que escojer uno de forma aleatoria\n",
    "        while is_not_max:\n",
    "            aleatorio_maximo = random.choice(acciones_posibles)\n",
    "            if q[estado][aleatorio_maximo] == maximo:\n",
    "                is_not_max = False\n",
    "\n",
    "        res = aleatorio_maximo\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_F2(data, recompensas, q, fin, epochs, gamma, epsilon, alpha, bol_camino, inicio):\n",
    "    rendimiento = []\n",
    "    for epoch in range(0, epochs):\n",
    "        \n",
    "\n",
    "        print('Época = '+str(epoch), 'Completado al '+str((epoch/epochs)*100)+'%')\n",
    "        i = np.random.randint(len(data) ,size=1)[0]\n",
    "        j = np.random.randint(len(data[i]),size=1)[0]\n",
    "        estado = data[i][j]\n",
    "        primero = True\n",
    "        epsilon_prima = epsilon\n",
    "        while (estado != fin) or (primero):\n",
    "            #print(epsilon,alpha)\n",
    "            accion = selecionar_accion_aleatoria_F2(estado, recompensas, q, epsilon)\n",
    "            maximo = max(q[accion])\n",
    "            q[estado][accion] = recompensas[estado][accion] + gamma*maximo\n",
    "            estado = accion\n",
    "            primero = False\n",
    "            epsilon_prima *= alpha\n",
    "\n",
    "        rendimiento.append(calcula_rendimiento(q))\n",
    "\n",
    "        \n",
    "        if bol_camino:\n",
    "            calcular_camino(q, inicio, fin)\n",
    "\n",
    "    print('Entrenamiento finalizado')\n",
    "    return q, rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del algoritmo SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(data, recompensas, q, fin, epochs, gamma, alpha, bol_camino, inicio):\n",
    "    rendimiento = []\n",
    "    for epoch in range(0, epochs):\n",
    "        \n",
    "        print('Época = '+str(epoch), 'Completado al '+str((epoch/epochs)*100)+'%')\n",
    "        i = np.random.randint(len(data) ,size=1)[0]\n",
    "        j = np.random.randint(len(data[i]),size=1)[0]\n",
    "        estado = data[i][j]\n",
    "        primero = True\n",
    "        \n",
    "        while (estado != fin) or (primero):\n",
    "            \n",
    "            accion = seleccionar_accion_aleatoria(estado, recompensas)\n",
    "            estado2 = accion\n",
    "            accion2 = seleccionar_accion_aleatoria(accion, recompensas)\n",
    "            q[estado][accion] = q[estado][accion] +alpha*(recompensas[estado][accion] + gamma*q[estado2][accion2] - q[estado][accion])\n",
    "            estado = accion\n",
    "            primero = False\n",
    "            \n",
    "        rendimiento.append(calcula_rendimiento(q))\n",
    "        if bol_camino:\n",
    "            calcular_camino(q, inicio, fin)\n",
    "    print('Entrenamiento finalizado')\n",
    "    return q, rendimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de representación en forma de Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_vertices(recompensas):\n",
    "    vertices = []\n",
    "    \n",
    "    for i in range(0,len(recompensas)):\n",
    "        vertices.append(i)\n",
    "        \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_aristas(recompensas):\n",
    "    aristas = []\n",
    "    \n",
    "    for i in range(0,len(recompensas)):\n",
    "        for j in range(0,len(recompensas)):\n",
    "            if recompensas[i][j]>=0:\n",
    "                aristas.append([i,j])\n",
    "                \n",
    "    return aristas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_colores(camino, recompensas, inicio, fin):\n",
    "    color_map = []\n",
    "    for i in range(0, len(recompensas)):\n",
    "        if i in camino:\n",
    "            if i == inicio or i == fin:\n",
    "                color_map.append('yellow')\n",
    "            else:\n",
    "                color_map.append('red')\n",
    "        else:\n",
    "            color_map.append('cyan')\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestra_grafo_camino(q,recompensas,inicio,fin):\n",
    "    \n",
    "    camino, converge = calcular_camino(q, inicio, fin)\n",
    "    if converge:\n",
    "        grafo = nx.Graph()\n",
    "        grafo.add_nodes_from(crea_vertices(recompensas))\n",
    "        grafo.add_edges_from(crea_aristas(recompensas))\n",
    "        color_map = crea_colores(camino, recompensas, inicio, fin)\n",
    "        print('''\n",
    "Leyenda:\n",
    "inicio/fin = amarillo\n",
    "camino escogido = rojo\n",
    "resto de casillas = azul\n",
    "        ''')\n",
    "        plt.figure()\n",
    "        nx.draw_spring(grafo, with_labels=True, font_weight='bold', node_color=color_map)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recopilación de todo en una función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecuta_QLearning():\n",
    "    \n",
    "    data, recompensas, q, inicio, fin, epochs, gamma = cargar_datos()\n",
    "    \n",
    "    camino_intermedio = int(input('Si quiere que se muestren los caminos intermedios pulse 1: '))\n",
    "    eleccion = int(input('''¿Qué algoritmo quieres usar?\n",
    "1 - Algoritmo Q_learning fase 1\n",
    "2 - Algoritmo Q_learning fase 2\n",
    "3 - Algoritmo SARSA: '''))\n",
    "    bol_camino = camino_intermedio == 1\n",
    "    \n",
    "    if eleccion == 1:\n",
    "        q, rendimiento  = q_learning(data, recompensas, q, fin, epochs, gamma, bol_camino, inicio)\n",
    "    \n",
    "    elif eleccion == 2:\n",
    "        \n",
    "        epsilon = float(input('Introduce el valor del parámetro epsilon: '))\n",
    "        alpha = float(input('Introduce el valor del parámetro alpha: '))\n",
    "        \n",
    "        q, rendimiento  = q_learning_F2(data, recompensas, q, fin, epochs, gamma, epsilon, alpha, bol_camino, inicio)\n",
    "    \n",
    "    elif eleccion == 3:\n",
    "        \n",
    "        alpha = float(input('Introduce el valor del parámetro alpha: '))\n",
    "        q, rendimiento = sarsa(data, recompensas, q, fin, epochs, gamma, alpha, bol_camino, inicio)\n",
    "        \n",
    "    print('\\nMatriz Q obtenida =\\n')\n",
    "    for i in range(len(q)):\n",
    "        print(str(i)+':',q[i])\n",
    "        \n",
    "    muestra_rendimiento(rendimiento)\n",
    "    \n",
    "    muestra_grafo_camino(q,recompensas,inicio,fin)\n",
    "        \n",
    "    return q, recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guia de uso de la función \"*ejecuta_QLearning()*\":\n",
    "\n",
    "La función \"*ejecuta_QLearning()*\" es la que recopila todo el código escrito anteriormente, y permite al usuario utilizar los 3 algoritmos desarrollados anteriormente. Para usar esta función, se le pedirá al usuario que aporte unos datos, los cuales explicaremos ahora:\n",
    "\n",
    "***Algunas preguntas podrán variar no aparecer dependiendo de las respuestas que se den a las mismas***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Quieres que se genere la matriz de recompensas a partir de un tablero?\n",
    "\n",
    "    - En el caso de introducir 0 el propio algorimo generará una matriz de recompensas.\n",
    "    - Sí se pulsa 1, el usuario luego tendrá que proveer de un txt donde se encuentre una matriz de recompensas lista para ser usada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Introduce el valor de la casilla de inicio\n",
    "\n",
    "     - El usuario tendrá de indicar cual es el valor de la casilla de partida. La casilla debe de estar contenida en el tablero que se está usando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Introduce el valor de la casilla de fin\n",
    "\n",
    "    - El usuario tendrá que indicar cúal es el calor de la casilla de parada. En el caso de estar usando una casilla de recompensas generada de forma manual, el valor de la casilla de fin deberá de ser consecuente con las recompensas que se han introducido. Si no, al algoritmo le costará mas encontrar soluciones. La casilla deberá de estar contenida en el tablero que se está usando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Introduce el numero de episodios de entrenamiento\n",
    "\n",
    "    - El usuario deberá de introducir el número de episodios de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Introduce el valor del factor de aprendicaje gamma.\n",
    "\n",
    "    - El usuario deberá de introducir un número entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "6. Introduce el nombre delfichero desde el que quieres cargar la matriz del tablero.\n",
    "\n",
    "    - El usuario debe de indicar cúal es el txt donde se encuentra contenido el tablero.\n",
    "    - Sólo habrá que indicar el nombre, el algoritmo buscará el automáticamente un documento txt que coincida con el nombre indicado dentro del directorio donde este contenido el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Introduce el nombre del fichero desde el que quieres cargar la matriz de recompensas\n",
    "\n",
    "    - El usuario debe de indicar cúal es el txt donde se encuentra contenido la matriz de recompensas.\n",
    "    - Sólo habrá que indicar el nombre, el algoritmo buscará el automáticamente un documento txt que coincida con el nombre indicado dentro del directorio donde este contenido el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Si quiere que se muestren los caminos intermedios pulse 1\n",
    "\n",
    "    - Si el usuario quiere ver los caminos intermedios que encuentra el algoritmo al final de cada época, debe introducir 1. En caso contrario el algoritmo no los mostrará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. ¿Qué algoritmo quieres usar?\n",
    "    - Si el usuario introduce 1, se usará el algoritmo de Q_Learning fase 1.\n",
    "    - Si el usuario introduce 2, se usará el algoritmo de Q_Learning fase 2.\n",
    "    - Si el usuario introduce 3, se usará el algoritmo SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Introduce el valor del parámetro epsilon\n",
    "    - El usuario deberá de introducir un parámetro entre 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Introduce el valor del parámetro alpha\n",
    "    - El usuario deberá de introducir un parámetro entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si quieres que se genere la matriz de recompensas a partir de un tablero pulsa 0,\n",
      "si quieres cargar tu matriz de recompensas pulsa 1: 1\n",
      "Introduce el valor de la casilla de inicio: 0\n",
      "Introduce el valor de la casilla objetivo: 6\n",
      "Introduce el número de episodios de entrenamiento: 30\n",
      "Introduce el valor del factor de aprendizaje gamma: 0.5\n",
      "Introduce el nombre del fichero desde el que quieres cargar los datos: ejemplo\n",
      "Introduce el nombre del fichero desde el que quieres cargar la matriz de recompensas: recompensas\n",
      "Si quiere que se muestren los caminos intermedios pulse 1: 3\n",
      "¿Qué algoritmo quieres usar?\n",
      "1 - Algoritmo Q_learning fase 1\n",
      "2 - Algoritmo Q_learning fase 2\n",
      "3 - Algoritmo SARSA: 1\n",
      "Época = 0 Completado al 0.0%\n",
      "Época = 1 Completado al 3.3333333333333335%\n",
      "Época = 2 Completado al 6.666666666666667%\n",
      "Época = 3 Completado al 10.0%\n",
      "Época = 4 Completado al 13.333333333333334%\n",
      "Época = 5 Completado al 16.666666666666664%\n",
      "Época = 6 Completado al 20.0%\n",
      "Época = 7 Completado al 23.333333333333332%\n",
      "Época = 8 Completado al 26.666666666666668%\n",
      "Época = 9 Completado al 30.0%\n",
      "Época = 10 Completado al 33.33333333333333%\n",
      "Época = 11 Completado al 36.666666666666664%\n",
      "Época = 12 Completado al 40.0%\n",
      "Época = 13 Completado al 43.333333333333336%\n",
      "Época = 14 Completado al 46.666666666666664%\n",
      "Época = 15 Completado al 50.0%\n",
      "Época = 16 Completado al 53.333333333333336%\n",
      "Época = 17 Completado al 56.666666666666664%\n",
      "Época = 18 Completado al 60.0%\n",
      "Época = 19 Completado al 63.33333333333333%\n",
      "Época = 20 Completado al 66.66666666666666%\n",
      "Época = 21 Completado al 70.0%\n",
      "Época = 22 Completado al 73.33333333333333%\n",
      "Época = 23 Completado al 76.66666666666667%\n",
      "Época = 24 Completado al 80.0%\n",
      "Época = 25 Completado al 83.33333333333334%\n",
      "Época = 26 Completado al 86.66666666666667%\n",
      "Época = 27 Completado al 90.0%\n",
      "Época = 28 Completado al 93.33333333333333%\n",
      "Época = 29 Completado al 96.66666666666667%\n",
      "Entrenamiento finalizado\n",
      "\n",
      "Matriz Q obtenida =\n",
      "\n",
      "0: [0, 24.99542236328125, 0, 16.25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1: [12.497711181640625, 0, 12.5, 0, 49.9908447265625, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2: [0, 24.99542236328125, 0, 6.25, 0, 25.0, 0, 6.25, 0, 0, 0, 0, 0, 0, 0]\n",
      "3: [12.497711181640625, 0, 12.5, 0, 0, 0, 0, 0, 3.125, 0, 0, 0, 0, 0, 0]\n",
      "4: [0, 24.99542236328125, 0, 0, 0, 49.997711181640625, 0, 0, 0, 99.981689453125, 0, 0, 0, 0, 0]\n",
      "5: [0, 0, 12.5, 0, 49.9908447265625, 0, 12.5, 0, 0, 0, 99.99542236328125, 0, 0, 0, 0]\n",
      "6: [0, 0, 0, 0, 0, 25.0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0]\n",
      "7: [0, 0, 12.5, 0, 0, 0, 12.5, 0, 3.125, 0, 0, 0, 0, 0, 0]\n",
      "8: [0, 0, 0, 6.25, 0, 0, 0, 6.25, 0, 0, 0, 0, 0, 0, 0]\n",
      "9: [0, 0, 0, 0, 49.9908447265625, 0, 0, 0, 0, 0, 99.99542236328125, 0, 0, 199.96337890625, 0]\n",
      "10: [0, 0, 0, 0, 0, 49.997711181640625, 0, 0, 0, 99.981689453125, 0, 49.997711181640625, 0, 0, 199.9908447265625]\n",
      "11: [0, 0, 0, 0, 0, 0, 12.5, 0, 0, 0, 99.99542236328125, 0, 49.99542236328125, 0, 0]\n",
      "12: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49.997711181640625, 0, 0, 99.9908447265625]\n",
      "13: [0, 0, 0, 0, 0, 0, 0, 0, 0, 99.981689453125, 0, 0, 0, 199.981689453125, 99.9908447265625]\n",
      "14: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99.99542236328125, 0, 49.99542236328125, 199.981689453125, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU5d3//9c7YQl7WMKOLAqIWHCJW92wVqyte91atWptrfdPb62trdr2W9Fu9r61tcvt2qpo3bFudQHca11BEEFEkUX2EJAtkECSz++Pc40MIZkckkxmJvk8H495ZM51ts85ZzLXnOu6znXJzHDOOefqk5fpAJxzzuUGzzCcc87F4hmGc865WDzDcM45F4tnGM4552LxDMM551wsnmG0MpLOl/R60vQmScMauK05ksY1WXBNpOYx1rPsPZJ+3cD9LJL01YasG2Pbt0n6f+nY9q7alfPZ0mTrZzxTPMPIAuGLZ0v48l4ZvsQ6N8e+zayzmS1o4LqjzeyVxsYgaYKkfzR2Oy2JmV1sZr8CkDRO0tJMx9RQko6X9I6kMklrJP1D0oB61jFJezRXjHVpqs94S+EZRvY4wcw6A/sA+wLXZDgelyGS8jMdQ1ORdBrwAPAnoBcwGtgK/FtSYYZja5PJ/ecizzCyjJmtBCYTZRwASGov6UZJn0laFYorOoR54yQtlfRjSSWSVki6IGndnpKekrRB0jvA7sn7S/4lF+5sbpH0XLjb+Y+kvpJulvS5pI8k7Zu07hdFMpLyJF0t6dPwK/IRST3CvCFhP+eFYyiV9PMw72vAz4Azwz7fD+n9Q9xrJc2X9P26zlmMY9xT0tSwrXmSzohzLSTtLumlcDylku6v60tOUgdJE8N5mivpp8l3BZJGSXpF0rpQzHFi0rx7JN0q6VlJZcBRiaIySZ2A54D+4fxsCudmgqRHw6/1jZI+kDRC0jXhc7BE0vikfTT7+ZQk4Cbg12Z2v5ltCZ/v7wGbgctjXIbatvvdcI4/lzRZ0uCkeX8Kx75B0nRJhyfNmyBpUjhnG4DzQ9ojku4N53GOpOKkdZI/4/Utu5+kGWHeo5IeVgOLO7OVZxhZRtJA4DhgflLy74ERRJnIHsAA4JdJ8/sC3UL6hcD/Seoe5v0fUA70A74bXqmcAfyC6NdgBfAm8F6YngT8oY71LgNOBo4E+gOfh30nOwwYCRwN/FLSKDN7Hvgt8HAoHhsbln0QWBq2dRrwW0lH17HvOo8xfOFOJfqV2xv4FnCLpNH1nAcAAb8LMYwCBgET6lj2WmAIMAw4BjgnKYa2wNPAlBDDfwP3SxqZtP63gd8AXYAv6gvMrIzo87A8nJ/OZrY8zD4BuA/oDswg+qGRR/Q5uB64PWn7mTifI4HdgEeTE82sGngMGF/LOilJOpnoB8apQBHw73BsCe8S/Z/0CDE+Kqkgaf5JRJ/jQuD+kHYi8FBIewr4a4oQal1WUjvgceCesO8HgVN29fiynpn5K8MvYBGwCdgIGPAiUBjmCSgDdk9a/hBgYXg/DtgCtEmaXwIcDOQD24A9k+b9Fng9adqAPcL7e4A7k+b9NzA3afpLwLoacX81vJ8LHJ00r1/YdxuiL1IDBibNfwc4K7yfAPwjad4goArokpT2O+CeWs5dymMEzgT+XWOd24Frk4751zGv08nAjDqOfwFwbNK87wFLw/vDgZVAXtL8B4EJSTHcW2NfX8QVrvHSGvMnAFOTpk8In6H8MN0lnPPC5jyfNdIPCzEU1DLvYuDjFOf6i89ljfTngAuTpvOI7lYG17Gdz4GxSefstVrO4wtJ03sBW+q4xnUuCxwBLAOUNP/1uJ+tXHn5HUb2ONnMuhB9OexJ9Iseol9RHYHpoThjHfB8SE9YY2aVSdObgc5hmTbAkqR5i+uJY1XS+y21TNdVGT8YeDwpxrlEX1J9kpZZWUuMtekPrDWzjTXirq2itL5jHAwclIgrxHY20V1ZSpJ6S3pI0rJQhPEPtl+X2mJOjmFJzXkW/bKu63iSl4+r5rUpNbOqpGmIznGmzmdp+Nuvlnn9gNXwRUukRHHb4bUsm2ww8Kekfa8l+lE1IGzrx6G4an2Y340dr1lt57nm57JAdddv1LVsf2CZhZwixb5ymmcYWcbMXiX6dXljSCol+ucfbWaF4dXNogry+qwGKol+YSbs1pTxJlkCHJcUY6GZFZjZshjr1uwyeTnQQ1KXpLTdiH7B1VTfMS4BXq0RV2cz+68Ycf0uxDbGzLoSFTOpjmVXAAOTppPjWQ4MkpT8/1bzeFJ1G93YLqUzdT7nERWDnZ6cGM7DN4FX4YuWSInitn/XcyxLgB/U2H8HM3sjZDZXERWrdjezQmA9O16zdHXPvQIYEOptEgbVtXCu8gwjO90MHCNpn/Cr9E7gj5J6A0gaIOnY+jYSfm3+E5ggqaOkvYDz0hTzbcBvEhWQkooknRRz3VXAkMQXqpktAd4AfiepQNIYorqZ+2uuGOMY/wWMkHSupLbhdYCkUTHi6kJUzLNOUTPQn6RY9hHgGkndw7KXJs17m6hY8adh/+OIipAeihEDROenp6RuMZffQabOZ/i1fSXwC0nfVtQwoC/wN6Jf/X+pJ/R2Id7EK5/oc3ZNos5EUjdJiQypC1FmtxpoI+mXQNd4Z6nR3iS6o75UUpvw2T+wmfbdbDzDyEJmthq4F0g8uHUVUSX4W6Fo5AWiCsU4LiUqllhJdOdyd5MGu92fiCoBp0jaCLwFHBRz3USl6BpJ74X33yKq+1hOVJl4rZlNrWP9Oo8xFMOMB84K21pJ1IigfYy4rgP2I/qV+gzRF2ldrif6Nb2Q6PpMImo0gJltJaosPY7ojvEW4Dtm9lGMGAjLPQgsCEUx/eOsV0NGzqeZPQycC1wBrCH6JX4AcKSZragn5jlEd9eJ1wVm9njY30Phf2E20XmFqNL/OeBjomK0cpqpWChc41OJMuJ1RHej/yJ8BloK7Vjk5pxrCpL+i6hS/8hMx5JNFDX1fZCogcTMTMeTTpLeBm4zs3T9SGt2fofhXBOQ1E/SoYqeRxkJ/Jjol7xLYmZTgPOJWvG1KJKOVPTcUhtJ5wFjiBqotBj+pKNzTaMdUfPSoURFEg8RFT25Gszs6UzHkCYjieqyOgOfAqfFKHbLKV4k5ZxzLhYvknLOOReLZxjOOediaZF1GL169bIhQ4ZkOgznnMsp06dPLzWzorrmt8gMY8iQIUybNi3TYTjnXE6RlLLrIC+Scs45F4tnGM4552LxDMM551wsnmE455yLxTMM55xzsXiG4ZxzLpYW2azWOedyQXV1erpmysura5yvxklbhiHpLuB4oMTM9g5p/0s0cMxWos65LjCzdWHeNUR9yVcBl5nZ5JD+NaKxFvKBv5nZDemK2TnnmssVD8/k8RlxBqTcNfsMKuSJSw5t8u1Ceu8w7gH+SjQQUMJU4Bozq5T0e+Aa4KowqtdZwGiisXFfkDQirPN/wDFEg9O8K+kpM/swjXE751xavb9kHY/PWMaxo/uwV78GDaRYp77d4owN1jBpyzDM7DVJQ2qkTUmafAs4Lbw/CXjIzCqAhZLms314w/lmtgBA0kNhWc8wnHM568Yp8+jesS03nj6WLgVtMx1ObJms9P4u0XCKAAPYcSjFpSGtrnTnnMtJby9Yw78/KeX/G7dHTmUWkKEMQ9LPiQZrTwxCX1sNjaVIr22bF0maJmna6tWrmyZQ55xrQmbGjVPm0adre849ZHCmw9llzZ5hhKELjwfOtu2jNy0FBiUtNpBogPm60ndiZneYWbGZFRcV1dnZonPOZcwrH6/m3UWfc+lXhlPQNj/T4eyyZs0wQounq4ATzWxz0qyngLMktZc0FBgOvAO8CwyXNFRSO6KK8aeaM2bnnGsKZsZNU+YxsHsHziweVP8KWSidzWofBMYBvSQtBa4lahXVHpgqCeAtM7vYzOZIeoSoMrsSuMTMqsJ2LgUmEzWrvcvM5qQrZuecS5fnZ69k9rIN3HT6WNq1yc1nplvkmN7FxcXm42E457JFVbVx7M2vATD5h0eQn6YH6xpL0nQzK65rfm5mc845l0OemLGM+SWb+NExI7I2s4jDMwznnEujrZXV3Pzix4zu35Wvje6b6XAaxTMM55xLo0emLWHJ2i1ceezItPXx1FxiVXpL6gMcECbfMbOS9IXknHMtQ/m2Kv7y0icUD+7OuBG539y/3jsMSWcQNXE9HTgDeFvSaanXcs45d9+bi1m1oYIrjx1JaBma0+LcYfwcOCBxVyGpCHgBmJTOwJxzLpdtqqjk1lc/5fDhvTh4WM9Mh9Mk4tRh5NUogloTcz3nnGu17np9IWvLtvLj8SMzHUqTiXOH8bykycCDYfpMtnca6JxzroZ1m7dy52sLGL9XH/YZVJjpcJpMvRmGmf1E0jeBQ4k6A7zDzB5Pe2TOOZejbnt1AZu2VraouwuI2UrKzB6TNDWxvKQeZrY2rZE551wOKtlYzj1vLOTEsf0Z2bdLpsNpUvVmGJJ+AFwPbAGqie4yDBiW3tCccy733PLyp2yrMq746oj6F84xce4wrgRGm1lpuoNxzrlsYma8+eka7ntrMfNWbYy1zmdrNnNG8UCG9OqU5uiaX5wM41Ngc71LOedcC7GpopLH31vKxDcXM79kE907tuWQ3XuSF+NZin0GFXLFMS3v7gLiZRjXAG9IehuoSCSa2WVpi8o55zLg09WbuO/NxUyavpRNFZV8aUA3bjx9LMeP6ZeTAx41tTgZxu3AS8AHRHUYzjnXYlRVGy99VMK9by7i35+U0jZfHD+mP985ZDD7DCpsEU9oN5U4GUalmf0o7ZE451wdqquNqXNXUbqpov6FgcQwP1ZLYnLa2rKtPDptKcvWbaFv1wKuHD+CMw/YjaIu7Zsk7pYmTobxsqSLgKfZsUjKm9U655rFpOlL+eljs9Ky7YOH9eAX3xjFMXv1oU2+d2KRSpwM49vh7zVJad6s1jnXLMoqKrlxyjz23a2Q287Zn9gFREr82b6GtMMs2uTn0a1D26YKtcWLk2GMMrPy5ARJBWmKxznndnDHawso2VjBrefsT5+u/tWTSXHuv96Imeacc01q5fpybn/tU74xph/7D+6e6XBavTrvMCT1BQYAHSTty/a7uK5Ax2aIzTnXyt04ZR7V1XD11/bMdCiO1EVSxwLnAwOBPySlbwR+lsaYnHOOOcvX89h7S/n+4cMY1MN/o2aDOjMMM5sITJT0TTN7rBljcs61cmbGb56ZS2GHtlxy1B6ZDscFqYqkzjGzfwBDJO30HIaZ/aGW1ZxzrtFe+qiENz5dw4QT9vJWTFkkVZFUoueszs0RiHPOAWyrqua3z85lWK9OnH3w4EyH45KkKpK6XVI+sMHM/tiMMTnnWrGH3vmMT1eXcce5+9PWH6TLKimvhplVASc2UyzOuVZuQ/k2/vjCJxw0tAfH7NUn0+G4GmI9hyHpr5IOl7Rf4lXfSpLuklQiaXZSWg9JUyV9Ev52D+mS9GdJ8yXNSt6+pPPC8p9IOq9BR+mcywm3vPwpa8u28otv7OWd/mWhOBnGl4HRRKPu3RReN8ZY7x7gazXSrgZeNLPhwIthGuA4YHh4XQTcClEGA1wLHAQcCFybyGSccy3LkrWbues/Czl1vwF8aWC3TIfjalFv1yBmdlRDNmxmr0kaUiP5JGBceD8ReAW4KqTfa2YGvCWpUFK/sOzUREeHYVzxrwEPNiQm51z2+t/J88gT/OTYkZkOxdWh3jsMSd0k/UHStPC6SVJDs/8+ZrYCIPztHdIHAEuSllsa0upKry3OixIxrl69uoHhOecyYcZnn/PU+8v5/uHD6NetQ6bDcXWIUyR1F9HT3WeE1wbg7iaOo7bCSkuRvnOi2R1mVmxmxUVFRU0anHMufcyMXz8zl16d2/ODI3fPdDguhTgZxu5mdq2ZLQiv62h41+arQlET4W9JSF8KDEpabiCwPEW6c66FeG72SqYv/pwfjx9B5/ZxOtB2mRInw9gi6bDEhKRDgS0N3N9TQKKl03nAk0np3wmtpQ4G1ociq8nAeEndQ2X3+JDmnGsBKiqruOG5jxjZpwtnFA+qfwWXUXGy8/8i6lOqG1ER0VqiTglTkvQgUaV1L0lLiVo73QA8IulC4DPg9LD4s8DXgfnAZuACiEb1k/Qr4N2w3PU+0p9z2aO62igtq2DV+gpWbiiPXuu3sHpjBVXV9a9fsrGcz9ZuZuJ3DyQ/z5vRZjuZ1VolsPOCUlcAM9uQ1oiaQHFxsU2bNi3TYTjXYqzbvJWXPiph9rINrNywhZXry1m1oYJVG8qprN7xOyQ/T/Tq3I42efGe0j56VG+uP2nvdITtdpGk6WZWXNf8eu8wanY8GB6mWQ9MN7OZjY7QOZeVVq4vZ8qHK5k8ZyVvLVhLVbXRsV0+fbsV0LdrAQcN7UGfbgX061ZAn65RWr9uBfTs3N7vFlqoOEVSxeH1dJj+BlER0cWSHjWz/0lXcM655jW/ZFPIJFbx/pJ1AAwr6sRFRwzj2NF9GTOgG3meGbRacTKMnsB+ZrYJQNK1wCTgCGA64BlGK1OysZyFq8syGkNB23w6tc+nY7s2dGwX/W3XpuV1VGdmbKsytmyromJbFRWV1cQsRcYwqi3aRlRqlJgO86qjv2UVVbwyr4TJc1byabiuYwZ24yfHjuTY0X3Yo3eXtB2fyy1xMozdgK1J09uAwWa2RVJFesJy2cTMmLN8Ay99VMKLc1fx/tL1mQ6pVm3yRMd2+XRq34YO7fLpFDKR5N/DNbsnUvLcDP5wrqyqpnxbNeWVVVRsq2bLtirKw6s6ZgbRGPl54qChPfjOIUM4Zq8+9C/0h+fczuJkGA8QddeRaAJ7AvCgpE7Ah2mLzGVU+bYq3vx0DS/MXcVLH5WwYn05EowdWMiV40cwdlAh+RnqHM5CfGVbq9iytZKyiio2b61k89aq8KqkbGsVmysq2ZrUVKfmL/Pkaav9edBm07FdG3p0yqN923wK2uTToV0eBW3yKWibT0HbvPA3n/Zt8sjbhfOel8cXy+dJSFEmmaco85RE23yx76DudO/ULl2H51qIOH1J/UrSs8BhRL/BLjazRBOks9MZnGteqzdW8OLcVbz4UQmvf1LKlm1VdGyXz+HDe3HFMSM4amRvirq0z3SYzrkMSTVEa4+kyYXh9cU8fx6iZVmxfgvj//AaGysq6d+tgNP2H8jRo3pz8LCeFLTNz3R4zrkskOoOYzo79ueUuGdXeN/Q7kFcFnpy5nI2VlTy8EUHc+DQHj4WgXNuJ6mGaB3anIG4zHpixjL2262Qg4b1zHQozrksFaunr9CP03CgIJFmZq+lKyjXvOau2MBHKzfyq5NGZzoU51wWi/Ok9/eAy4l6ip0JHAy8CXwlvaG55vLEjGW0yRPfGNM/06E457JYnCedLgcOABaH0ff2BXyEohaiqtp4cuZyxo0sooc3q3TOpRAnwyg3s3IASe3N7CPAx1BsId5esIaVG8o5ed9aBzJ0zrkvxKnDWCqpEHgCmCrpc3wQoxbj8RnL6Ny+DV8d1SfToTjnslycB/dOCW8nSHoZ6AY8n9aoXLMo31bFc7NXctzeff1ZC+dcvXZpPEQzezVdgbjm98LcVWyqqOQUL45yzsXQ8rr3dLE9MWNZNK6BP3vhnIvBM4xWam3ZVl6Zt5qT9unvg90452LxDKOVembWciqrzVtHOediS9X54EZ27D8KtvctZWbWNc2xuTR6fMYy9uzbhVH9/DI65+JJ1ZeUD7PVQi1eU8Z7n63j6uP2zHQozrkcEqtIStJhki4I73tJ8o4Jc9gTM5YjwYljvSsQ51x89WYYYQzvq4BrQlI74B/pDMqlj5nxxMxlHDy0pw/D6ZzbJXHuME4BTgTKAMxsOeDFVTnq/aXrWVha5s9eOOd2WZwMY6uZGaECPIzl7XLUEzOW0a5NHl/7Ut9Mh+KcyzFxMoxHJN0OFEr6PvACcGd6w3LpsK2qmqffX84xo/rQtaBtpsNxzuWYejMMM7sRmAQ8RtRL7S/N7C+N2amkKyTNkTRb0oOSCiQNlfS2pE8kPSypXVi2fZieH+YPacy+W7PXPyllTdlWf/bCOdcgsVpJmdlUM/uJmV1pZlMbs0NJA4DLgGIz2xvIB84Cfg/80cyGA58DF4ZVLgQ+N7M9gD+G5VwDPD5jGYUd23LkiKJMh+Kcy0F1ZhiSNkraUNerkfttA3SQ1AboCKwgGsFvUpg/ETg5vD8pTBPmHy3J+7LYRZsqKpny4UqOH9OPdm38AX/n3K6r98E9SdcDK4H7iJ7yPptGtJIys2WSbgQ+A7YAU4DpwDozqwyLLQUS5SYDgCVh3UpJ64GeQGlDY2iNJs9eSfm2am8d5ZxrsDg/NY81s1vMbKOZbTCzW4FvNnSHkroT3TUMBfoDnYDjalm0Zrcktc1L3u5FkqZJmrZ6tY8gW9MTM5cxqEcH9tute6ZDcc7lqDgZRpWksyXlS8qTdDZQ1Yh9fhVYaGarzWwb8E/gy0StsBJ3PAPZPqrfUmAQQJjfDVhbc6NmdoeZFZtZcVGRl9EnW7WhnP/ML+WUfQbgpXnOuYaKk2F8GzgDWBVep4e0hvoMOFhSx1AXcTTwIfAycFpY5jzgyfD+qTBNmP9SeC7ExfT0+8upNjjJi6Occ40QZ4jWRURFSE3CzN6WNAl4D6gEZgB3AM8AD0n6dUj7e1jl78B9kuYT3Vmc1VSxtBaPz1jG2IHd2L2oc6ZDcc7lsF0aorWpmNm1wLU1khcAB9aybDnRXY1rgI9XbWTO8g1ce8JemQ7FOZfjMpJhuPSpqjYWlm7i/SXrmbV0Ha/PLyU/Txw/xnumdc41jmcYOczMWLJ2C7OWrWPW0vW8v2Qds5etp2xr1CahY7t89h7QjR8csTtFXdpnOFrnXK6rN8OQ1A2YABwekl4Frjez9WmMy6Wwraqayx+awZufruHzzdsAaJefx6j+Xfnm/gMZM7CQsQO7Mayos4/X7ZxrMnHuMO4CZhO1lAI4F7gbODVdQbnU5pds4tkPVvKVPXtz9KjejBlQyMi+XfwJbudcWsXJMHY3s+QH9a6TNDNdAbn6LSotA+BHx4xg7wHdMhyNc661iPOTdIukwxITkg4l6tLDZcjCNVGGMaSXD03inGs+ce4wLgbuDXUZEPUke16K5V2aLS7dTK/O7enc3tssOOeaT5xvnA1mNlZSVwAz2yBpaJrjciksXFPGkJ4dMx2Gc66ViVMk9RhEGYWZJbo1n5RieZdmi9eUeXGUc67Z1XmHIWlPYDTQTVJyi6iuQEG6A3O127y1klUbKvwOwznX7FIVSY0EjgcKgROS0jcC309nUK5ui0o3A17h7ZxrfqkGUHoSeFLSIWb2ZjPG5FJYnGgh1dMzDOdc84pT6T1f0s+AIcnLm9l30xWUq5s3qXXOZUqcDONJ4N/ACzRu4CTXBLxJrXMuU+J863Q0s6vSHomLZeGaMob28gpv51zzi9Os9l+Svp72SFwsi0rLGOz1F865DIiTYVxOlGmUS9ogaaOkDfWu5Zrc5q2VlGysYKjXXzjnMiDOEK1dmiMQV79Ek9rB/gyGcy4D6r3DUOQcSf8vTA+StNNQqi79FnmTWudcBsUpkroFOAT4dpjeBPxf2iJydVrkTWqdcxkUp5XUQWa2n6QZAGb2uaR2aY7L1WJRaZk3qXXOZUycO4xtkvIBA5BUBFSnNSpXq0VrNnuTWudcxsTJMP4MPA70lvQb4HXgt2mNytVqUWmZ11845zImTiup+yVNB44GBJxsZnPTHpnbQVlF1KTW6y+cc5mSqnvzrmGwpB5ACfBg0rweZra2OQJ0kcVrQi+1fofhnMuQVHcYDxB1bz6dqP5CNf4OS3t07guJFlL+DIZzLlNSdW9+fPjb5MOxSioE/gbsTZT5fBeYBzxM1CvuIuCM0CJLwJ+ArwObgfPN7L2mjinbLSz1JrXOucyKU+mNpDGSTpR0auLVyP3+CXjezPYExgJzgauBF81sOPBimAY4DhgeXhcBtzZy3zlp8Zoyirp4k1rnXObU++0j6S5gDDCH7c1pDfhnQ3YoqStwBHA+gJltBbZKOgkYFxabCLwCXAWcBNxrZga8JalQUj8zW9GQ/eeqRaWbfVhW51xGxfm5erCZ7dWE+xwGrAbuljSWqI7kcqBPIhMwsxWSeoflBwBLktZfGtJaV4axpowjRxRlOgznXCsWp0jqTUlNmWG0AfYDbjWzfYEythc/1Ua1pNlOC0kXSZomadrq1aubJtIs4U1qnXPZIE6GMZEo05gnaZakDyTNasQ+lwJLzeztMD2JKANZJakfQPhbkrT8oKT1BwLLa27UzO4ws2IzKy4qalm/xL3TQedcNohTJHUXcC7wAU3QJYiZrZS0RNJIM5tH9EDgh+F1HnBD+PtkWOUp4FJJDwEHAetbW/3FF89geLcgzrkMipNhfGZmTzXxfv8buD90YrgAuIDobucRSRcCnwGnh2WfJWpSO5+oWe0FTRxL1ks0qfWR9pxzmRQnw/hI0gPA00BFItHMGtRKKqw7EyiuZdbRtSxrwCUN3VdLsKjUm9Q65zIvzjdQB6KMYnxSWoOb1bpdt3jNZob63YVzLsPidD7Y6oqAss3CNWWM8ya1zrkMS9X54E/N7H8k/YVamrGa2WVpjcwBUZPa1d6k1jmXBVLdYSS6MJ/WHIG42nmTWudctkjV+eDT4e/E5gvH1bSo1JvUOueyQ6oiqaeppSgqwcxOTEtEbgd+h+GcyxapiqRuDH9PBfoC/wjT3yLqftw1g0ST2k7epNY5l2GpiqReBZD0KzM7ImnW05JeS3tkDojuMLxJrXMuG8TpS6pI0hej60kaCngbz2ayaM1mr79wzmWFOOUcVwCvSFoQpocAP0hbRO4Lm0KTWu8SxDmXDeI8uPe8pOHAniHpIzOrSLWOaxqLQ4X3UH8GwzmXBeLWpO5PdGfRBhgrCTO7N21ROWB7k9rBPtKecy4LxBmi9T5gd2AmUBWSDfAMI828Sa1zLpvEucMoBvYKvca6ZrSotIze3qTWOZcl4rSSmk30HIZrZovWlPndhXMua8T56doL+FDSO+w4HoY/6Z1mC1/EVCkAABTQSURBVEs385U9vQWzcy47xMkwJqQ7CLezTRWVlG7yXmqdc9kjTrPaVyUNBoab2QuSOgL56Q+tdVtU6hXezrnsUm8dhqTvA5OA20PSAOCJdAblolH2wDMM51z2iFPpfQlwKLABwMw+AXqnMyi3vUmtP4PhnMsWcTKMCjPbmpiQ1IYU3Z67prHQm9Q657JMnAzjVUk/AzpIOgZ4FHg6vWG5xWvKvMLbOZdV4mQYVwOrgQ+IOh18FvhFOoNyUZPaIV4c5ZzLIinLOyTlAxPN7BzgzuYJyXmTWudcNkp5h2FmVUTjYbRrpngc25vU+sBJzrlsEqdGdRHwH0lPAWWJRDP7Q7qCau22t5DyDMM5lz3iZBjLwysP6JLecBwkPYPhI+0557JInCe9r0vHjkP9yDRgmZkdH4Z+fQjoAbwHnGtmWyW1J+pKfX9gDXCmmS1KR0zZItGktmM7b1LrnMsecVpJpcvlwNyk6d8DfzSz4cDnwIUh/ULgczPbA/hjWK5FW1TqTWqdc9knIxmGpIHAN4C/hWkBXyHqggRgInByeH9SmCbMPzos32ItWrPZK7ydc1knU3cYNwM/BarDdE9gnZlVhumlRH1WEf4uAQjz14fldyDpIknTJE1bvXp1OmNPq43l2yjdVMFgr79wzmWZOgvJJf2FFF2AmNllDdmhpOOBEjObLmlcIrm2XcSYlxzPHcAdAMXFxTnbdUmiwtvvMJxz2SZVreq0NO3zUOBESV8HCoCuRHcchZLahLuIgUQtsyC62xgELA39WHUD1qYptozzJrXOuWxVZ4ZhZhOTpyV1MrOyupaPy8yuAa4J2xwHXGlmZ0t6FDiNqKXUecCTYZWnwvSbYf5LLXl88S/GwfAiKedclokzHsYhkj4ktGiSNFbSLWmI5SrgR5LmE9VR/D2k/x3oGdJ/RNS3VYu1aM1m+nT1JrXOuewT51vpZuBYol/6mNn7ko5oip2b2SvAK+H9AuDAWpYpB05viv3lgkWlZV4c5ZzLSrFaSZnZkhpJVWmIxRHVYXiFt3MuG8W5w1gi6cuAhU4IL2PHB+5cE4ma1G71h/acc1kpzh3GxUTDtA4garG0T5h2TWz7ON5e4e2cyz5x+pIqBc5uhlhavUSTWr/DcM5lo2Z/cM/VLdGkdrDfYTjnslCqIqlpwHSih+v2Az4Jr33wSu+0+GDZegYUdvAmtc65rFTvg3uSzgeOMrNtYfo2YEqzRNeKlG+r4rWPS/nm/gPqX9g55zIgTqV3f3YcOKlzSHNN6LWPV7NlWxXHju6b6VCcc65Wcco+bgBmSHo5TB8JTEhbRK3U5Dmr6FrQhoOH7dQRr3POZYU4raTulvQccFBIutrMVqY3rNalsqqaFz9axdGj+tA2P5NjWjnnXN1i1a6GDOLJehd0DfLOwrWs27yNY0f3yXQozjlXJ/85mwUmz1lJ+zZ5HDGiKNOhOOdcnTzDyDAzY8qHqzhiRJE3p3XOZbWUGYakPEmzmyuY1mjW0vWsWF/uraOcc1kvZYZhZtXA+5J2a6Z4Wp0pH64kP08cvWfvTIfinHMpxSkD6QfMkfQO8MWIe2Z2YtqiakUmz1nFgUN60L1Tu0yH4pxzKcXJMK5LexSt1KerNzG/ZBPnHOQ3cM657BfnOYxXJfUBDghJ75hZSXrDah0mz4keZxnv9RfOuRwQZ0zvM4B3iIZJPQN4W9Jp6Q6sNZg8ZxVjBnajf2GHTIfinHP1ilMk9XPggMRdhaQi4AVgUjoDa+lWri/n/SXr+MmxIzMdinPOxRLnOYy8GkVQa2Ku51KY8mFUHOVPdzvnckWcO4znJU0GHgzTZwLPpi+k1mHynJUMK+rEHr271L+wc85lgTiV3j+R9E3gUEDAHWb2eNoja8HWbd7KWwvWctERwzIdinPOxRa388HHgMfSHEur8eLcEqqqzZ/uds7llFRjem+k9jG9BZiZdU1bVC3c5Dkr6du1gDEDumU6FOeciy3VEK1euJ4GW7ZW8donqzmjeBB5ecp0OM45F1vs1k6SekvaLfFq6A4lDZL0sqS5kuZIujyk95A0VdIn4W/3kC5Jf5Y0X9IsSfs1dN/Z4NWPV1O+rdqLo5xzOSfOg3snSvoEWAi8CiwCnmvEPiuBH5vZKOBg4BJJewFXAy+a2XDgxTANcBwwPLwuAm5txL4zbsqclXTr0JYDh/bIdCjOObdL4txh/Iroi/1jMxsKHA38p6E7NLMVZvZeeL8RmAsMAE4CJobFJgInh/cnAfda5C2gUFK/hu4/k7ZVVfPC3FUcPaq3D8XqnMs5cb61tpnZGiBPUp6ZvQzs0xQ7lzQE2Bd4G+hjZisgylSARH/fA4AlSastDWk55+0Fa9lQXunFUc65nBSnWe06SZ2B14D7JZUQFSs1StjmY8APzWyDVGcFcG0zdmq9JekioiIrdtstO3t/nfLhSgra5nHEcB+K1TmXe+LcYZwEbAGuAJ4HPgVOaMxOJbUlyizuN7N/huRViaKm8DfRHclSYFDS6gOB5TW3aWZ3mFmxmRUXFWXfF3J1tTFlziqOGF5Eh3b5mQ7HOed2WZ0ZhqS/SvqymZWZWZWZVZrZRDP7cyiiahBFtxJ/B+aa2R+SZj0FnBfenwc8mZT+ndBa6mBgfaLoKpfMWraelRt8KFbnXO5KVST1CXBT+LX/MPCgmc1sgn0eCpwLfCApsb2fATcAj0i6EPiMqDt1iPqt+jowH9gMXNAEMTS7yXPCUKyjfChW51xuSvXg3p+AP0kaDJwF3C2pgKgTwofM7OOG7NDMXqf2egmIWmDVXN6ASxqyr2wyec5KDh7Wg8KOPhSrcy431VuHYWaLzez3ZrYv8G3gFKKmsC6m+SUbWbC6zIujnHM5Lc6De20lnSDpfqIH9j4Gvpn2yFqQyXNWATB+L88wnHO5K1Xng8cA3wK+QTRE60PARWZW1kyxZbWtldUsKN2E1dY9Yw3PfrCCsYMK6dutIP2BOedcmqSq9P4Z8ABwpZmtbaZ4csLydVu4cOI05q7YEHudq4/bM40ROedc+qWq9D6qOQPJFe8vWcf37p3Glq1V/OaUvenZqf5K7Py8PA4f3qsZonPOufSJNYCSizwzawU/emQmRV3ac//3DmJEH+8B3jnXeniGEYOZ8deX5nPT1I/Zf3B37jh3f3p2bp/psJxzrll5hlGP8m1VXP3YLJ6YuZxT9h3A7079EgVtvWsP51zr4xlGCqWbKvjBfdOZvvhzrhw/gkuO2oMUnSQ651yL5hlGHT5etZHv3vMupZsquOXs/fj6l3JyCA7nnGsynmHU4pV5JVz6wAw6tMvn4YsOYeygwkyH5JxzGecZRg0T31jEdU/PYc++XfnbecX0L+yQ6ZCccy4reIaRZH7JJq7/14ccPaoPN5+5D53a++lxzrkE/0ZMskfvzjx68SHsM7CQvDyv3HbOuWSeYdSw327dMx2Cc85lpThDtDrnnHOeYTjnnIvHMwznnHOxeIbhnHMuFs8wnHPOxeIZhnPOuVg8w3DOOReLLM6g1DlG0mpgcSM20QsobaJwskFLOx5oecfU0o4HWt4xtbTjgZ2PabCZFdW1cIvMMBpL0jQzK850HE2lpR0PtLxjamnHAy3vmFra8cCuH5MXSTnnnIvFMwznnHOxeIZRuzsyHUATa2nHAy3vmFra8UDLO6aWdjywi8fkdRjOOedi8TsM55xzsXiG4ZxzLhbPMJJI+pqkeZLmS7o60/E0BUmLJH0gaaakaZmOZ1dJuktSiaTZSWk9JE2V9En4m1ODmNRxTBMkLQvXaaakr2cyxl0haZCklyXNlTRH0uUhPSevU4rjyeVrVCDpHUnvh2O6LqQPlfR2uEYPS2qXcjtehxGRlA98DBwDLAXeBb5lZh9mNLBGkrQIKDaznHzgSNIRwCbgXjPbO6T9D7DWzG4IGXt3M7sqk3HuijqOaQKwycxuzGRsDSGpH9DPzN6T1AWYDpwMnE8OXqcUx3MGuXuNBHQys02S2gKvA5cDPwL+aWYPSboNeN/Mbq1rO36Hsd2BwHwzW2BmW4GHgJMyHFOrZ2avAWtrJJ8ETAzvJxL9M+eMOo4pZ5nZCjN7L7zfCMwFBpCj1ynF8eQsi2wKk23Dy4CvAJNCer3XyDOM7QYAS5Kml5LjH5LAgCmSpku6KNPBNJE+ZrYCon9uoHeG42kql0qaFYqscqL4piZJQ4B9gbdpAdepxvFADl8jSfmSZgIlwFTgU2CdmVWGRer9zvMMYzvVktYSyusONbP9gOOAS0JxiMs+twK7A/sAK4CbMhvOrpPUGXgM+KGZbch0PI1Vy/Hk9DUysyoz2wcYSFSiMqq2xVJtwzOM7ZYCg5KmBwLLMxRLkzGz5eFvCfA40Qcl160K5cyJ8uaSDMfTaGa2KvxDVwN3kmPXKZSLPwbcb2b/DMk5e51qO55cv0YJZrYOeAU4GCiU1CbMqvc7zzOM7d4FhodWA+2As4CnMhxTo0jqFCrtkNQJGA/MTr1WTngKOC+8Pw94MoOxNInEF2twCjl0nUKF6t+BuWb2h6RZOXmd6jqeHL9GRZIKw/sOwFeJ6mZeBk4Li9V7jbyVVJLQTO5mIB+4y8x+k+GQGkXSMKK7CoA2wAO5dkySHgTGEXXDvAq4FngCeATYDfgMON3McqYSuY5jGkdU1GHAIuAHifL/bCfpMODfwAdAdUj+GVG5f85dpxTH8y1y9xqNIarUzie6UXjEzK4P3xEPAT2AGcA5ZlZR53Y8w3DOOReHF0k555yLxTMM55xzsXiG4ZxzLhbPMJxzzsXiGYbbiaRLwkNLzjn3Bc8wWhFJJummpOkrQ6d3ycucC/RI6ncm4yTdI+m0+pds8Pb7S5pU/5L1bmeCpCvD++slfbXx0e2w/UWSejXlNmtsf59s64FV0huNWPd8Sf2bMp7WzjOM1qUCOLWeL5184Nfp2HnSE6VZxcyWm1mTZkhm9ksze6Ept9kM9gFqzTAyde3M7MuNWP18wDOMJuQZRutSSTSG7xU1ZyR+xZvZPWZmkjaF9HGSXpX0iKSPJd0g6ezQt/4HknYPyxVJekzSu+F1aEifIOkOSVOAe0O//HeHdWdIOqqWWCTpr5I+lPQMSZ3WSdo/xDNd0uQaT98mlkkVy32SXlLU///3Q/oQhbEpJI0OxzYzdDI3PKT/SNLs8Pph0r5+rmgMlReAkTXPZ3h/dDjWDxR1Wtc+pN8QjnGWpJ26zJbUU9KUsO7tJPV3JumcpDhvV9Q9f831az1Xkl6R9Puw/seSDlfUu8H1wJlhm2fWcu3yJf1vOKezJP0g6TPyiqRJkj6SdL8khXm/DMvPDttSUgx/lPSaonEnDpD0z3Bdfp10DJuS3v8kad+J8RyGhPXvVDTOwxRJHcK5LwbuD8fToa7r4HaBmfmrlbyIxmDoSvSUajfgSmBCmHcPcFrysuHvOGAd0A9oDywDrgvzLgduDu8fAA4L73cj6lYBYALReAIdwvSPgbvD+z2JngAuqBHnqUS9aeYT/UJcR9R9QVvgDaAoLHcm0RP5NY8zVSzvAx2InrJeErY/BJgdlvkLcHZ43y4suz/RU7+dgM7AHKIeTBPpHcN5nQ9cmXw+gYKwnxEh/V7gh0RP1s5j+8OzhbUcx5+BX4b33yB6wrgXUadxTwNtw7xbgO/UWLfOc0XUj9BN4f3XgRfC+/OBvyZto+a1uwj4RXjfHpgGDCX6jKwn6osoD3gz6fz3SNrefcAJSTH8PulztJztn7GlQM8an8PxRD92FPbxL+CIcO0qgX3Cco8QPa2c2EdxeF/rdcj0/2SuvbKyiMClj5ltkHQvcBmwJeZq71roAkHSp8CUkP4BkLhD+CqwV/gBCdBVoR8r4CkzS+zrMKIvZczsI0mLgRHArKT9HQE8aGZVwHJJL4X0kcDewNSwn3yiXkNrShXLkyGWLZJeJupAbmbSum8CP5c0kGhgmU8UdRXxuJmVhXPwT+Bwoi+ux81sc0ivre+xkcBCM/s4TE8ELgH+CpQDfwt3Uf+qZd0jiDJPzOwZSZ+H9KOJMqt3wzF2YOeO/eo7V4kOAqcTfenWJfnajQfGaHt9UjdgOLAVeMfMlgIo6kJ7CNEgPUdJ+ilRptqDKLN9OrHt8PcDYE7SZ2wBUUega5LiGB9eM8J057Dvz4jOb+Ia1nU8dV2Hm1Mcu6vBM4zW6WbgPeDupLRKQhFlKDZIHqoxuW+Z6qTparZ/hvKAQ5K+XAjbAihLTooZY2191ojoi+WQetZNFUvN7e4wbWYPSHqb6Bf9ZEnfqyfm+vrWqXVdM6uUdCDRl/9ZwKVEg9nE2b6AiWZ2TT37TXWuEtewitTfAzWv3X+b2eQddiSNY8fPSBXQRlIB0d1PsZktUdTAoqCWGKrZ+TNWMyYBvzOz22vse0gt++5Qy3HE/dy5FLwOoxWyqAO4R4ALk5IXEf1qhWiktLa7uNkpRF96QNTipo7lXgPODsuMICoymlfLMmeFMvN+bL+LmQcUSTokrN9W0uhdjOUkRfUoPYmKUt5NXlFRZ2wLzOzPRL+Ax4R4TpbUUVGvv6cQdU73GnBKKB/vApxQSywfAUMk7RGmzwVeVdRsuZuZPUtURFXb+Uo+V8cBiQF7XgROk9Q7zOshaXCNdeOeq2QbgS4p5k8G/ktR199IGhHOR10SmUNpON7GNCyYDHw3bAdJAxLHn0Ly8dR6HRoRT6vkGUbrdRNReXjCncCRkt4BDmLHX5ZxXAYUhwrJD4GL61juFiBf0gfAw8D5tnPvmI8DnxAVVdxK+Me2aOjc04DfS3qfqCiptlY0qWJ5B3gGeAv4lYXxQpKcCcwOxSp7Eo27/R5RncQ7RD2w/s3MZoT0h0McjxFlIjsws3LgAuDRcMzVwG1EX2T/kjQrHN9ODRGA64AjJL1HVBzzWdjmh8AviEZSnEVU37ND5f8unKtkLxMV5c2UdGYt8/8GfAi8p6iRwO2kuDuxaNyFO4mu4xPUyJx3hZlNIaqbejOcx0mkztwguma3hWspar8Obhd4b7Wu1QhFIpvMbKcWSc65+vkdhnPOuVj8DsM551wsfofhnHMuFs8wnHPOxeIZhnPOuVg8w3DOOReLZxjOOedi8QzDOedcLP8/oGW0loDUZrwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El algoritmo ha entrado en bucle al buscar un camino\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "    \n",
    "    q, recompensas = ejecuta_QLearning()\n",
    "    \n",
    "if __name__ == \"__main__\": main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
